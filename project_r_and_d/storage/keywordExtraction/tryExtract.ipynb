{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc869e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole text to be used\n",
      " VECTORIZATION OF TEXT USING DATA MINING METHODS, In the text mining tasks, textual representation should be not only efficient but also interpretable, as this enables an understanding of the operational logic underlying the data mining models. Traditional text vectorization methods such as TF-IDF and bag-of-words are effective and characterized by intuitive interpretability, but suffer from the «curse of dimensionality», and they are unable to capture the meanings of words. On the other hand, modern distributed methods effectively capture the hidden semantics, but they are computationally intensive, time-consuming, and uninterpretable. This article proposes a new text vectorization method called Bag of weighted Concepts BoWC that presents a document according to the concepts’ information it contains. The proposed method creates concepts by clustering word vectors (i.e. word embedding) then uses the frequencies of these concept clusters to represent document vectors. To enrich the resulted document representation, a new modified weighting function is proposed for weighting concepts based on statistics extracted from word embedding information. The generated vectors are characterized by interpretability, low dimensionality, high accuracy, and low computational costs when used in data mining tasks. The proposed method has been tested on five different benchmark datasets in two data mining tasks; document clustering and classification, and compared with several baselines, including Bag-of-words, TF-IDF, Averaged GloVe, Bag-of-Concepts, and VLAC. The results indicate that BoWC outperforms most baselines and gives 7% better accuracy on average\n"
     ]
    }
   ],
   "source": [
    "# TRY YAKE\n",
    "title = \"VECTORIZATION OF TEXT USING DATA MINING METHODS\"\n",
    "text = \"In the text mining tasks, textual representation should be not only efficient but also interpretable, as this enables an understanding of the operational logic underlying the data mining models. Traditional text vectorization methods such as TF-IDF and bag-of-words are effective and characterized by intuitive interpretability, but suffer from the «curse of dimensionality», and they are unable to capture the meanings of words. On the other hand, modern distributed methods effectively capture the hidden semantics, but they are computationally intensive, time-consuming, and uninterpretable. This article proposes a new text vectorization method called Bag of weighted Concepts BoWC that presents a document according to the concepts’ information it contains. The proposed method creates concepts by clustering word vectors (i.e. word embedding) then uses the frequencies of these concept clusters to represent document vectors. To enrich the resulted document representation, a new modified weighting function is proposed for weighting concepts based on statistics extracted from word embedding information. The generated vectors are characterized by interpretability, low dimensionality, high accuracy, and low computational costs when used in data mining tasks. The proposed method has been tested on five different benchmark datasets in two data mining tasks; document clustering and classification, and compared with several baselines, including Bag-of-words, TF-IDF, Averaged GloVe, Bag-of-Concepts, and VLAC. The results indicate that BoWC outperforms most baselines and gives 7% better accuracy on average\"\n",
    "full_text = title +\", \"+ text \n",
    "print(\"The whole text to be used\\n\",full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a72051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "722e4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a0bdc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kw_extractor.extract_keywords(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93977808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyphrase:  operational logic underlying : score 0.008502958451052589\n",
      "Keyphrase:  text vectorization methods : score 0.015613284939549285\n",
      "Keyphrase:  text vectorization : score 0.02310717508615897\n",
      "Keyphrase:  Traditional text vectorization : score 0.02325791341228692\n",
      "Keyphrase:  data mining models : score 0.02830809004349318\n",
      "Keyphrase:  data mining tasks : score 0.033863083795882626\n",
      "Keyphrase:  DATA MINING : score 0.03618462463953267\n",
      "Keyphrase:  text mining tasks : score 0.037652251074155374\n",
      "Keyphrase:  enables an understanding : score 0.04036782511075581\n",
      "Keyphrase:  operational logic : score 0.04036782511075581\n"
     ]
    }
   ],
   "source": [
    "for kw, v in keywords:\n",
    "    print(\"Keyphrase: \", kw, \": score\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9732c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Rake\n",
    "from multi_rake import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b0aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = rake.apply(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3dc1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data mining methods', 9.0)\n",
      "('operational logic underlying', 9.0)\n",
      "('data mining models', 9.0)\n",
      "('modified weighting function', 9.0)\n",
      "('weighting concepts based', 9.0)\n",
      "('data mining tasks', 9.0)\n",
      "('weighted concepts bowc', 8.5)\n",
      "('low computational costs', 8.5)\n",
      "('text mining tasks', 8.0)\n",
      "('represent document vectors', 7.916666666666666)\n",
      "('clustering word vectors', 7.833333333333332)\n",
      "('resulted document representation', 7.75)\n",
      "('word embedding information', 7.666666666666666)\n",
      "('word embedding', 5.166666666666666)\n",
      "('document clustering', 4.75)\n",
      "('generated vectors', 4.666666666666666)\n",
      "('textual representation', 4.5)\n",
      "('concepts’ information', 4.5)\n",
      "('bowc outperforms', 4.5)\n",
      "('hidden semantics', 4.0)\n",
      "('computationally intensive', 4.0)\n",
      "('article proposes', 4.0)\n",
      "('concept clusters', 4.0)\n",
      "('statistics extracted', 4.0)\n",
      "('low dimensionality', 4.0)\n",
      "('benchmark datasets', 4.0)\n",
      "('averaged glove', 4.0)\n",
      "('intuitive interpretability', 3.5)\n",
      "('high accuracy', 3.5)\n",
      "('proposed method', 3.5)\n",
      "('document', 2.25)\n",
      "('text', 2.0)\n",
      "('dimensionality', 1.5)\n",
      "('proposed', 1.5)\n",
      "('interpretability', 1.5)\n",
      "('accuracy', 1.5)\n",
      "('vectorization', 1.0)\n",
      "('efficient', 1.0)\n",
      "('interpretable', 1.0)\n",
      "('enables', 1.0)\n",
      "('understanding', 1.0)\n",
      "('tf-idf', 1.0)\n",
      "('bag-of-words', 1.0)\n",
      "('effective', 1.0)\n",
      "('characterized', 1.0)\n",
      "('suffer', 1.0)\n",
      "('curse', 1.0)\n",
      "('unable', 1.0)\n",
      "('capture', 1.0)\n",
      "('meanings', 1.0)\n",
      "('words', 1.0)\n",
      "('hand', 1.0)\n",
      "('time-consuming', 1.0)\n",
      "('uninterpretable', 1.0)\n",
      "('presents', 1.0)\n",
      "('frequencies', 1.0)\n",
      "('enrich', 1.0)\n",
      "('tested', 1.0)\n",
      "('classification', 1.0)\n",
      "('compared', 1.0)\n",
      "('baselines', 1.0)\n",
      "('bag-of-concepts', 1.0)\n",
      "('vlac', 1.0)\n",
      "('results', 1.0)\n",
      "('average', 1.0)\n"
     ]
    }
   ],
   "source": [
    "for i in keywords:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
