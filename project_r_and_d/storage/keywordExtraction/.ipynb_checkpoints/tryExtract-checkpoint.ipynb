{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a4afc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole text to be usedn VECTORIZATION OF TEXT USING DATA MINING METHODS, In the text mining tasks, textual representation should be not only efficient but also interpretable, as this enables an understanding of the operational logic underlying the data mining models. Traditional text vectorization methods such as TF-IDF and bag-of-words are effective and characterized by intuitive interpretability, but suffer from the «curse of dimensionality», and they are unable to capture the meanings of words. On the other hand, modern distributed methods effectively capture the hidden semantics, but they are computationally intensive, time-consuming, and uninterpretable. This article proposes a new text vectorization method called Bag of weighted Concepts BoWC that presents a document according to the concepts’ information it contains. The proposed method creates concepts by clustering word vectors (i.e. word embedding) then uses the frequencies of these concept clusters to represent document vectors. To enrich the resulted document representation, a new modified weighting function is proposed for weighting concepts based on statistics extracted from word embedding information. The generated vectors are characterized by interpretability, low dimensionality, high accuracy, and low computational costs when used in data mining tasks. The proposed method has been tested on five different benchmark datasets in two data mining tasks; document clustering and classification, and compared with several baselines, including Bag-of-words, TF-IDF, Averaged GloVe, Bag-of-Concepts, and VLAC. The results indicate that BoWC outperforms most baselines and gives 7% better accuracy on average\n"
     ]
    }
   ],
   "source": [
    "# TRY YAKE\n",
    "title = \"VECTORIZATION OF TEXT USING DATA MINING METHODS\"\n",
    "text = \"In the text mining tasks, textual representation should be not only efficient but also interpretable, as this enables an understanding of the operational logic underlying the data mining models. Traditional text vectorization methods such as TF-IDF and bag-of-words are effective and characterized by intuitive interpretability, but suffer from the «curse of dimensionality», and they are unable to capture the meanings of words. On the other hand, modern distributed methods effectively capture the hidden semantics, but they are computationally intensive, time-consuming, and uninterpretable. This article proposes a new text vectorization method called Bag of weighted Concepts BoWC that presents a document according to the concepts’ information it contains. The proposed method creates concepts by clustering word vectors (i.e. word embedding) then uses the frequencies of these concept clusters to represent document vectors. To enrich the resulted document representation, a new modified weighting function is proposed for weighting concepts based on statistics extracted from word embedding information. The generated vectors are characterized by interpretability, low dimensionality, high accuracy, and low computational costs when used in data mining tasks. The proposed method has been tested on five different benchmark datasets in two data mining tasks; document clustering and classification, and compared with several baselines, including Bag-of-words, TF-IDF, Averaged GloVe, Bag-of-Concepts, and VLAC. The results indicate that BoWC outperforms most baselines and gives 7% better accuracy on average\"\n",
    "full_text = title +\", \"+ text \n",
    "print(\"The whole text to be usedn\",full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73584772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe90168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677e852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kw_extractor.extract_keywords(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d13fcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyphrase:  operational logic underlying : score 0.008502958451052589\n",
      "Keyphrase:  text vectorization methods : score 0.015613284939549285\n",
      "Keyphrase:  text vectorization : score 0.02310717508615897\n",
      "Keyphrase:  Traditional text vectorization : score 0.02325791341228692\n",
      "Keyphrase:  data mining models : score 0.02830809004349318\n",
      "Keyphrase:  data mining tasks : score 0.033863083795882626\n",
      "Keyphrase:  DATA MINING : score 0.03618462463953267\n",
      "Keyphrase:  text mining tasks : score 0.037652251074155374\n",
      "Keyphrase:  enables an understanding : score 0.04036782511075581\n",
      "Keyphrase:  operational logic : score 0.04036782511075581\n"
     ]
    }
   ],
   "source": [
    "for kw, v in keywords:\n",
    "    print(\"Keyphrase: \", kw, \": score\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ccaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY RAKE\n",
    "!conda install -c conda-forge multi_rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c3593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc7b7d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'multi_rake'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8724\\344427319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmulti_rake\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'multi_rake'"
     ]
    }
   ],
   "source": [
    "from multi_rake import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3c5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
